# Flamingo项目说明

Flamingo论文[Flamingo论文](paper/deepmind-Flamingo.pdf)  
实现tensorflow1.15 keras class风格的实现  

## Vision Encoder
见[Vision Encoder实现](Vision_Encoder.py)  
Vision Encoder按照原论文中应使用NFNet Normalizer-Free ResNet。  
由于带有seq_len结构的图像模型Vit Vision Transformer也很契合，因此ViT应该也很适合于当前场景。  
本实现为仅仅使用ResNet50进行reshape实现的seq_len的概念，理念与当前场景不符，需要后续改进。  

## Perceiver Resampler
见[Perceiver Resampler](Perceiver_Resampler.py)  
Perceiver Resampler的输入是Vision Encoder的输出，其主要作用是对图像特征进行降维，降低后续运算的复杂度。  
实现方式就是self-attention + ffw  

## Text_Embedding
见[Text Embedding](Text_Embedding.py)  
Text_Embedding方法对输入的文本token进行embedding 包括word_embedding, token_type_embedding, position_embedding  
最后将上述三者进行顺序连接，构建Text Embedding对象。  
三个矩阵的参数从pre_trained Chinese Bert中导入 见load_bert_weights方法  

## Gated_XATTN_Dense
见[Gated XATTN Dense](Gated_XATTN_Dense.py)  
实现图像特征与文本特征的cross_attention方法  
目前的实现还未实现media_mask部分，同时仅实现了单个位置多张图像算法  

## LM_Block
见[LM Block](LM_Block.py)  
实现基本的self-attention + FFW方法  
self-attention和ffw的参数从pre_trained Chinese Bert中导入 见load_bert_weights方法  

## Fused_Transformer
fused_transformer融合了上述所有组件，构建最终的Flamingo模型  
进行prompt learning完成指定的任务  

## utils
utils中实现了ffw方法  

## modeling
仅使用了modeling方法中的get_shape_list，这个方法在静态图的tf1中十分有用  
还使用了gelu激活函数  

## vocab.txt
在本任务中加入了[IMAGE] token  

## tokenization
对文本进行token的方法集合 十分有用  
有basic tokenizer和wordpiece结合的full tokenizer  

## data_process
### calculate_image_embedding
见[calculate image embedding](data_process/calculate_image_embedding.py)  
该方法在服务器上运行，提前计算好图像的embedding保存下来  
### data_process
见[data process](data_process/data_process.ipynb)  
data_process从原始文本数据生成prompt文本  
主要步骤：
1. \t分隔两个句子
2. 转为unicode
3. tokenize basic_tokenize + wordpiece_tokenize
4. mask掉包装方式位置 生成masked_position masked_ids
5. 生成[CLS] + [IMAGE] + 文本1 +[SEP] + 文本2 + [MASK] + [SEP]的形式
6. 生成各种ids
7. 保存为pkl

## load_pretrained_BERT
从bert4keras库中得到keras风格的bert模型  
之后使用load_weights set_weights方法进行参数提取与导出  