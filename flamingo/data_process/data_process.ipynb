{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "from PIL import Image\n",
    "import tokenization\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                    product_spu_name  \\\n0           jason/捷森 低脂牛奶 240ml 德国进口   \n1      【24盒】蒙牛特仑苏有机纯牛奶利乐梦幻盖250ml×24包   \n2                         菊乐250ml纯牛奶   \n3              伊利 利乐包纯牛奶250mL*16盒 /箱   \n4        【整箱】伊利 营养纯牛奶小纯奶 250ml*24盒/箱   \n...                              ...   \n18148        托本莫瑞 12年单一麦芽威士忌 700ml/瓶   \n18149  日本 响威士忌【正品行货 防伪码】洋酒烈酒 700ml/瓶   \n18150          格兰菲迪 麦芽威士忌40度 700ml盒装   \n18151        道格拉斯 美食家麦芽威士忌洋酒 700ml/瓶   \n18152            尊尼获加黑牌黑方苏格兰威士忌700ml   \n\n                                         product_picture property  \n0      http://p1.meituan.net/sgopen/18c6fae4044b41910...       瓶装  \n1      http://p0.meituan.net/xianfu/a016be57a13051a20...       箱装  \n2      http://p0.meituan.net/xianfu/12c40a4415a2619fe...       盒装  \n3      http://p0.meituan.net/wmproduct/815e983175af66...       箱装  \n4      https://p0.meituan.net/xianfu/e4724d6cfcc2f23f...       箱装  \n...                                                  ...      ...  \n18148  http://p1.meituan.net/xianfu/21385b5b7ff21cb42...       瓶装  \n18149  http://p0.meituan.net/scproduct/cf68bcced2a3b5...       瓶装  \n18150  http://p0.meituan.net/waimaidpoipicmining/6447...       盒装  \n18151  http://p1.meituan.net/wmproduct/13c24535b35c99...       瓶装  \n18152  http://p1.meituan.net/wmproduct/9ca36e2b0da8cf...       瓶装  \n\n[18146 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>product_spu_name</th>\n      <th>product_picture</th>\n      <th>property</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>jason/捷森 低脂牛奶 240ml 德国进口</td>\n      <td>http://p1.meituan.net/sgopen/18c6fae4044b41910...</td>\n      <td>瓶装</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>【24盒】蒙牛特仑苏有机纯牛奶利乐梦幻盖250ml×24包</td>\n      <td>http://p0.meituan.net/xianfu/a016be57a13051a20...</td>\n      <td>箱装</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>菊乐250ml纯牛奶</td>\n      <td>http://p0.meituan.net/xianfu/12c40a4415a2619fe...</td>\n      <td>盒装</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>伊利 利乐包纯牛奶250mL*16盒 /箱</td>\n      <td>http://p0.meituan.net/wmproduct/815e983175af66...</td>\n      <td>箱装</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>【整箱】伊利 营养纯牛奶小纯奶 250ml*24盒/箱</td>\n      <td>https://p0.meituan.net/xianfu/e4724d6cfcc2f23f...</td>\n      <td>箱装</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>18148</th>\n      <td>托本莫瑞 12年单一麦芽威士忌 700ml/瓶</td>\n      <td>http://p1.meituan.net/xianfu/21385b5b7ff21cb42...</td>\n      <td>瓶装</td>\n    </tr>\n    <tr>\n      <th>18149</th>\n      <td>日本 响威士忌【正品行货 防伪码】洋酒烈酒 700ml/瓶</td>\n      <td>http://p0.meituan.net/scproduct/cf68bcced2a3b5...</td>\n      <td>瓶装</td>\n    </tr>\n    <tr>\n      <th>18150</th>\n      <td>格兰菲迪 麦芽威士忌40度 700ml盒装</td>\n      <td>http://p0.meituan.net/waimaidpoipicmining/6447...</td>\n      <td>盒装</td>\n    </tr>\n    <tr>\n      <th>18151</th>\n      <td>道格拉斯 美食家麦芽威士忌洋酒 700ml/瓶</td>\n      <td>http://p1.meituan.net/wmproduct/13c24535b35c99...</td>\n      <td>瓶装</td>\n    </tr>\n    <tr>\n      <th>18152</th>\n      <td>尊尼获加黑牌黑方苏格兰威士忌700ml</td>\n      <td>http://p1.meituan.net/wmproduct/9ca36e2b0da8cf...</td>\n      <td>瓶装</td>\n    </tr>\n  </tbody>\n</table>\n<p>18146 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv', index_col=0)\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data['text'] = data['product_spu_name'] + '\\t' + '\"包装方式\"属性为' + data['property']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "瓶装     11957\n盒装      1715\n箱装      1686\n罐装      1447\n袋装       530\n连包装      259\n礼盒装      232\n桶装       219\n杯装        92\n坛装         6\n散装         3\nName: property, dtype: int64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['property'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def split_and_tokenize(all_documents, tokenizer, data_pd, prod_num):\n",
    "    raw_text = data_pd['text'].iloc[prod_num]\n",
    "    # 得到由\\t分隔的两个句子\n",
    "    raw_text = raw_text.replace(\"<eop>\",\"\")\n",
    "    # 将eop替换为空\n",
    "    raw_text = tokenization.convert_to_unicode(raw_text)\n",
    "    # 转为unicode\n",
    "    two_sentence = raw_text.strip('\\n').split('\\t')\n",
    "    # 按照\\t分隔\n",
    "    for i in range(len(two_sentence)):\n",
    "        tokens = tokenizer.tokenize(two_sentence[i])\n",
    "        all_documents[-1].append(tokens)\n",
    "    all_documents.append([])\n",
    "    # 进行tokenize basic_tokenize + wordpiece tokenize"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "all_documents = [[]]\n",
    "tokenizer = tokenization.FullTokenizer(\n",
    "        vocab_file='vocab.txt', do_lower_case=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "for i in range(data.shape[0]):\n",
    "    split_and_tokenize(all_documents, tokenizer, data, i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "all_documents = [x for x in all_documents if x]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [],
   "source": [
    "def create_masked_lm_predictions(tokens):\n",
    "    if tokens[-3] in ['瓶', '箱', '盒', '袋', '罐', '杯', '桶', '散', '坛']:\n",
    "        masked_lm_labels = [tokens[-3]]\n",
    "        masked_lm_positions = [len(tokens)-3]\n",
    "    elif tokens[-4] in ['礼', '连']:\n",
    "        masked_lm_labels = [tokens[-4]]\n",
    "        masked_lm_positions = [len(tokens)-4]\n",
    "        # 进行mask 得到真实值和mask位置\n",
    "    else:\n",
    "        print(tokens)\n",
    "        return\n",
    "    output_tokens = tokens[:masked_lm_positions[0]] + [\"[MASK]\"] + [\"[SEP]\"]\n",
    "    # 句子 + [MASK] + [SEP]\n",
    "    return output_tokens, masked_lm_positions, masked_lm_labels\n",
    "\n",
    "def create_instances_from_document(all_documents, num, tokenizer):\n",
    "    document = all_documents[num]\n",
    "    tokens = []\n",
    "    tokens.append(\"[CLS]\")\n",
    "    tokens.append(\"[IMAGE]\")\n",
    "    token_type_ids = [0, 0]\n",
    "    for i in range(len(document)):\n",
    "        for token in document[i]:\n",
    "            tokens.append(token)\n",
    "            if i == 0:\n",
    "                token_type_ids.append(0)\n",
    "        tokens.append(\"[SEP]\")\n",
    "    # [CLS] + [IMAGE] + 文本1 + [SEP] + 文本2 + [SEP]\n",
    "    tokens, masked_lm_positions, masked_lm_labels = create_masked_lm_predictions(tokens)\n",
    "    while len(token_type_ids) < len(tokens):\n",
    "        token_type_ids.append(1)\n",
    "        # 对文本2 token为1\n",
    "    data_dict = all_data_to_np(tokens, masked_lm_positions, masked_lm_labels, token_type_ids, tokenizer)\n",
    "    return data_dict\n",
    "\n",
    "def all_data_to_np(tokens, masked_lm_positions, masked_lm_labels, token_type_ids, tokenizer, max_seq_len=512):\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    while len(input_ids) < max_seq_len:\n",
    "        input_ids.append(0)\n",
    "        token_type_ids.append(0)\n",
    "        # pad 0\n",
    "    masked_lm_ids = tokenizer.convert_tokens_to_ids(masked_lm_labels)\n",
    "    input_ids = np.array(input_ids, dtype=np.int32)\n",
    "    token_type_ids = np.array(token_type_ids, dtype=np.int32)\n",
    "    masked_lm_positions = np.array(masked_lm_positions, dtype=np.int32)\n",
    "    masked_lm_ids = np.array(masked_lm_ids, dtype=np.int32)\n",
    "    data_dict = dict()\n",
    "    data_dict['input_ids'] = input_ids\n",
    "    data_dict['token_type_ids'] = token_type_ids\n",
    "    data_dict['masked_lm_positions'] = masked_lm_positions\n",
    "    data_dict['masked_lm_ids'] = masked_lm_ids\n",
    "    return data_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "dict_ = create_instances_from_document(all_documents, 2, tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "all_data = dict()\n",
    "for i in range(len(all_documents)):\n",
    "    each_dict = create_instances_from_document(all_documents, i, tokenizer)\n",
    "    all_data[str(i).zfill(5)] = each_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [],
   "source": [
    "text_files = open('text_data.pkl', 'wb')\n",
    "pickle.dump(all_data, text_files)\n",
    "text_files.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "image_embedding_file = open('image_embedding.pkl', 'rb')\n",
    "image_embedding = pickle.load(image_embedding_file)\n",
    "image_embedding_file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "data": {
      "text/plain": "18146"
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_embedding.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "data": {
      "text/plain": "18146"
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [],
   "source": [
    "two_modal_data = dict()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [],
   "source": [
    "for i in range(len(image_embedding.keys())):\n",
    "    key = str(i).zfill(5)\n",
    "    two_modal_data[i] = dict()\n",
    "    two_modal_data[i]['image_embedding'] = image_embedding[key]\n",
    "    two_modal_data[i]['input_ids'] = all_data[key]['input_ids']\n",
    "    two_modal_data[i]['token_type_ids'] = all_data[key]['token_type_ids']\n",
    "    two_modal_data[i]['masked_lm_positions'] = all_data[key]['masked_lm_positions']\n",
    "    two_modal_data[i]['masked_lm_ids'] = all_data[key]['masked_lm_ids']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [],
   "source": [
    "two_modal_data_file = open('image_text_file.pkl', 'wb')\n",
    "pickle.dump(two_modal_data, two_modal_data_file)\n",
    "two_modal_data_file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}